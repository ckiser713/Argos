#
# Deployment env for Compose/systemd. Replace placeholders before use.
# Production: source secrets from a secret manager (Vault/SSM/SealedSecrets)
# or from a separate, untracked env file. Do not commit filled-in secrets.
#

# Core
CORTEX_ENV=strix
CORTEX_SKIP_AUTH=false
CORTEX_AUTH_SECRET=
CORTEX_ACCESS_TOKEN_MINUTES=15
CORTEX_REFRESH_TOKEN_DAYS=7
CORTEX_ALLOWED_ORIGINS=https://your-frontend.example

# Model root (host path) used by docker-compose.prod volume bind
MODELS_PATH=/data/cortex-models
# Optional tiny models for smoke tests (download with ops/download_minimal_models.sh)
CORTEX_MINIMAL_VLLM_MODEL_PATH=/models/minimal/vllm/TinyLlama-1.1B-Chat-v1.0
CORTEX_MINIMAL_GGUF_MODEL_PATH=/models/minimal/gguf/TinyLlama-1.1B-Chat-v1.0.Q4_K_M.gguf

# Runtime guard
RUNNING_IN_DOCKER=0  # set to 1 when running inside Docker/Compose
# Uncomment for non-Nix systemd/bare-metal deployments:
# CORTEX_ALLOW_NON_NIX=1

# Database
CORTEX_DATABASE_URL=postgresql://USER:PASS@HOST:5432/cortex
POSTGRES_PASSWORD=

# Services
CORTEX_QDRANT_URL=http://qdrant:6333
CORTEX_N8N_BASE_URL=http://n8n:5678
CORTEX_N8N_API_KEY=

# n8n UI credentials (use only when exposing the UI behind VPN/allowlist/auth proxy)
N8N_BASIC_AUTH_USER=
N8N_BASIC_AUTH_PASSWORD=
N8N_ENCRYPTION_KEY=

# Exposure & rate limits (defaults are conservative; override per environment)
N8N_ALLOWED_IPS=10.0.0.0/8 172.16.0.0/12 192.168.0.0/16
CORTEX_RATE_LIMIT_EVENTS=300
CORTEX_RATE_LIMIT_WINDOW=1m
CORTEX_RATE_LIMIT_BURST=50
CORTEX_WEBHOOK_RATE_EVENTS=120
CORTEX_WEBHOOK_RATE_WINDOW=1m
CORTEX_WEBHOOK_RATE_BURST=30

# LLM backend defaults
CORTEX_LLM_BACKEND=local_http
CORTEX_LLM_DEFAULT_LANE=orchestrator

# Lane configs
CORTEX_LANE_ORCHESTRATOR_URL=http://inference-vllm:8000/v1
CORTEX_LANE_ORCHESTRATOR_MODEL=Qwen3-30B-Thinking
CORTEX_LANE_ORCHESTRATOR_MODEL_PATH=/models/orchestrator/bf16
CORTEX_LANE_ORCHESTRATOR_BACKEND=vllm

CORTEX_LANE_CODER_URL=http://inference-vllm:8000/v1
CORTEX_LANE_CODER_MODEL=Qwen3-Coder-30B-1M
CORTEX_LANE_CODER_MODEL_PATH=/models/coder/bf16
CORTEX_LANE_CODER_BACKEND=vllm

CORTEX_LANE_FAST_RAG_URL=http://inference-vllm:8000/v1
CORTEX_LANE_FAST_RAG_MODEL=MegaBeam-Mistral-7B-512k
CORTEX_LANE_FAST_RAG_MODEL_PATH=/models/fast_rag/bf16
CORTEX_LANE_FAST_RAG_BACKEND=vllm

CORTEX_LANE_SUPER_READER_URL=http://llama-super-reader:8080/v1
CORTEX_LANE_SUPER_READER_MODEL=Nemotron-8B-UltraLong-4M
CORTEX_LANE_SUPER_READER_MODEL_PATH=/models/super_reader/model.gguf
CORTEX_LANE_SUPER_READER_BACKEND=llama_cpp

CORTEX_LANE_GOVERNANCE_URL=http://llama-governance:8081/v1
CORTEX_LANE_GOVERNANCE_MODEL=Granite-4.x-Long-Context
CORTEX_LANE_GOVERNANCE_MODEL_PATH=/models/governance/model.gguf
CORTEX_LANE_GOVERNANCE_BACKEND=llama_cpp

# ROCm / vLLM tuning
HIP_VISIBLE_DEVICES=0
HSA_OVERRIDE_GFX_VERSION=11.0.0
VLLM_TARGET_DEVICE=rocm
VLLM_ROCM_USE_AITER=1
VLLM_ROCM_USE_SKINNY_GEMM=1
GPU_MEM_UTIL=0.48
MAX_MODEL_LEN=32768

# Hugging Face cache (shared)
HF_HOME=/models/hf_cache
HF_TOKEN=
