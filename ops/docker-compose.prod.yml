# =============================================================================
# Cortex Production Docker Compose
# =============================================================================
# Full production stack with:
# - Caddy reverse proxy (auto-SSL)
# - PostgreSQL database
# - Qdrant vector database
# - vLLM inference (ROCm/Strix Halo)
# - llama.cpp for long-context models
# - n8n workflow automation
# - Backend (FastAPI)
# - Frontend (React, served via Caddy)
#
# Usage:
#   docker compose -f ops/docker-compose.prod.yml up -d
#
# Prerequisites:
#   - Copy ../.env.example to ../.env and configure
#   - Set MODELS_PATH to your host model root (e.g., /data/cortex-models)
#   - Download models: ./ops/download_all_models.sh
#   - (Optional) Minimal smoke models: ./ops/download_minimal_models.sh
# =============================================================================

version: '3.8'

# Shared environment variables
x-common-env: &common-env
  CORTEX_ENV: ${CORTEX_ENV:-strix}
  RUNNING_IN_DOCKER: "1"
  CORTEX_AUTH_SECRET: ${CORTEX_AUTH_SECRET:?CORTEX_AUTH_SECRET is required}
  CORTEX_DATABASE_URL: postgresql://cortex:${POSTGRES_PASSWORD:?POSTGRES_PASSWORD is required}@postgres:5432/cortex
  CORTEX_QDRANT_URL: http://qdrant:6333
  CORTEX_N8N_BASE_URL: http://n8n:5678
  CORTEX_LLM_BASE_URL: http://inference-vllm:8000/v1
   # Storage: default to local persistent volume unless explicitly set to s3/minio
  CORTEX_STORAGE_BACKEND: ${CORTEX_STORAGE_BACKEND:-local}
  CORTEX_ALLOW_LOCAL_STORAGE: ${CORTEX_ALLOW_LOCAL_STORAGE:-1}
  CORTEX_STORAGE_LOCAL_DIR: ${CORTEX_STORAGE_LOCAL_DIR:-/app/storage_uploads}
  CORTEX_STORAGE_BUCKET: ${CORTEX_STORAGE_BUCKET:-cortex-ingest}
  CORTEX_STORAGE_ENDPOINT_URL: ${CORTEX_STORAGE_ENDPOINT_URL:-}
  CORTEX_STORAGE_ACCESS_KEY: ${CORTEX_STORAGE_ACCESS_KEY:-}
  CORTEX_STORAGE_SECRET_KEY: ${CORTEX_STORAGE_SECRET_KEY:-}
  HF_TOKEN: ${HF_TOKEN:-}

x-model-paths: &model-paths
  CORTEX_LANE_ORCHESTRATOR_MODEL_PATH: /models/vllm/orchestrator/bf16
  CORTEX_LANE_CODER_MODEL_PATH: /models/vllm/coder/bf16
  CORTEX_LANE_FAST_RAG_MODEL_PATH: /models/vllm/fast_rag/bf16
  CORTEX_LANE_SUPER_READER_MODEL_PATH: /models/gguf/nemotron-8b-instruct.Q4_K_M.gguf
  CORTEX_LANE_GOVERNANCE_MODEL_PATH: /models/gguf/granite-3.0-8b-instruct.Q4_K_M.gguf

x-healthcheck-defaults: &healthcheck-defaults
  interval: 30s
  timeout: 10s
  retries: 3
  start_period: 60s

x-restart-policy: &restart-policy
  restart: unless-stopped

services:
  # ===========================================================================
  # Queue Broker - Redis
  # ===========================================================================
  redis:
    image: redis:7.2-alpine
    container_name: cortex-redis
    <<: *restart-policy
    command: ["redis-server", "--save", "", "--appendonly", "no"]
    healthcheck:
      test: ["CMD-SHELL", "redis-cli ping | grep PONG"]
      <<: *healthcheck-defaults
      start_period: 10s
    networks:
      - cortex-network

  # ===========================================================================
  # Model Preflight - verifies model paths exist before starting inference
  # ===========================================================================
  model-preflight:
    image: alpine:3.20
    container_name: cortex-model-preflight
    command: >
      sh -c "
        /preflight/model-preflight.sh ${CORTEX_LANE_ORCHESTRATOR_MODEL_PATH} &&
        /preflight/model-preflight.sh ${CORTEX_LANE_CODER_MODEL_PATH} &&
        /preflight/model-preflight.sh ${CORTEX_LANE_FAST_RAG_MODEL_PATH} &&
        /preflight/model-preflight.sh ${CORTEX_LANE_SUPER_READER_MODEL_PATH} &&
        /preflight/model-preflight.sh ${CORTEX_LANE_GOVERNANCE_MODEL_PATH}
      "
    environment:
      <<: *model-paths
    volumes:
      - cortex_models:/models:ro
      - ./model-preflight.sh:/preflight/model-preflight.sh:ro
    networks:
      - cortex-network
    restart: "no"

  # ===========================================================================
  # Reverse Proxy - Caddy with automatic HTTPS
  # ===========================================================================
  caddy:
    image: caddy:2.8.4-alpine
    container_name: cortex-caddy
    <<: *restart-policy
    ports:
      - "80:80"
      - "443:443"
      - "443:443/udp"  # HTTP/3
    environment:
      CORTEX_DOMAIN: ${CORTEX_DOMAIN:-localhost}
      CORTEX_ADMIN_EMAIL: ${CORTEX_ADMIN_EMAIL:-admin@localhost}
      # Rate limits (API and webhooks)
      CORTEX_RATE_LIMIT_EVENTS: ${CORTEX_RATE_LIMIT_EVENTS:-300}
      CORTEX_RATE_LIMIT_WINDOW: ${CORTEX_RATE_LIMIT_WINDOW:-1m}
      CORTEX_RATE_LIMIT_BURST: ${CORTEX_RATE_LIMIT_BURST:-50}
      CORTEX_WEBHOOK_RATE_EVENTS: ${CORTEX_WEBHOOK_RATE_EVENTS:-120}
      CORTEX_WEBHOOK_RATE_WINDOW: ${CORTEX_WEBHOOK_RATE_WINDOW:-1m}
      CORTEX_WEBHOOK_RATE_BURST: ${CORTEX_WEBHOOK_RATE_BURST:-30}
      # n8n UI/IP allowlist (defaults to private ranges; override for VPN/allowlist)
      N8N_ALLOWED_IPS: "${N8N_ALLOWED_IPS:-10.0.0.0/8 172.16.0.0/12 192.168.0.0/16}"
    volumes:
      - ./caddy/Caddyfile:/etc/caddy/Caddyfile:ro
      - caddy_data:/data
      - caddy_config:/config
      - frontend_dist:/srv/frontend:ro
    depends_on:
      backend:
        condition: service_healthy
    networks:
      - cortex-network
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:80/health"]
      <<: *healthcheck-defaults

  # ===========================================================================
  # Database - PostgreSQL
  # ===========================================================================
  postgres:
    image: postgres:15.8-alpine
    container_name: cortex-postgres
    <<: *restart-policy
    environment:
      POSTGRES_DB: ${POSTGRES_DB:-cortex}
      POSTGRES_USER: ${POSTGRES_USER:-cortex}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:?POSTGRES_PASSWORD is required}
      # Performance tuning for Strix Halo (128GB RAM)
      POSTGRES_INITDB_ARGS: "--encoding=UTF8 --locale=C"
    command:
      - "postgres"
      - "-c"
      - "shared_buffers=4GB"
      - "-c"
      - "effective_cache_size=12GB"
      - "-c"
      - "maintenance_work_mem=1GB"
      - "-c"
      - "checkpoint_completion_target=0.9"
      - "-c"
      - "wal_buffers=64MB"
      - "-c"
      - "default_statistics_target=100"
      - "-c"
      - "random_page_cost=1.1"
      - "-c"
      - "effective_io_concurrency=200"
      - "-c"
      - "work_mem=256MB"
      - "-c"
      - "min_wal_size=1GB"
      - "-c"
      - "max_wal_size=4GB"
      - "-c"
      - "max_connections=200"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./init-scripts:/docker-entrypoint-initdb.d:ro
    networks:
      - cortex-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U cortex -d cortex"]
      <<: *healthcheck-defaults
      start_period: 30s
    deploy:
      resources:
        limits:
          memory: 8G
        reservations:
          memory: 4G

  # ===========================================================================
  # Vector Database - Qdrant
  # ===========================================================================
  qdrant:
    image: qdrant/qdrant:1.13.3
    container_name: cortex-qdrant
    <<: *restart-policy
    volumes:
      - qdrant_data:/qdrant/storage
      - qdrant_snapshots:/qdrant/snapshots
    networks:
      - cortex-network
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:6333/health"]
      <<: *healthcheck-defaults
    deploy:
      resources:
        limits:
          memory: 8G
        reservations:
          memory: 4G

  # ===========================================================================
  # LLM Inference - vLLM (ROCm/Strix Halo)
  # ===========================================================================
  inference-vllm:
    # Set CORTEX_VLLM_IMAGE to a pinned tag (no :latest)
    image: ${CORTEX_VLLM_IMAGE:?CORTEX_VLLM_IMAGE must be set to a pinned tag}
    container_name: cortex-vllm
    <<: *restart-policy
    entrypoint: ["/bin/sh", "-c"]
    command: >
      /preflight/model-preflight.sh "${CORTEX_LANE_ORCHESTRATOR_MODEL_PATH}" &&
      exec python -m vllm.entrypoints.openai.api_server
        --model "${CORTEX_LANE_ORCHESTRATOR_MODEL_PATH}"
        --quantization fp8
        --kv-cache-dtype fp8
        --host 0.0.0.0
        --port 8000
    devices:
      - /dev/kfd
      - /dev/dri
    group_add:
      - video
      - render
    environment:
      <<: *model-paths
      VLLM_GPU_MEMORY_UTILIZATION: ${VLLM_GPU_MEMORY_UTILIZATION:-0.45}
      VLLM_ENFORCE_EAGER: ${VLLM_ENFORCE_EAGER:-true}
      VLLM_MAX_MODEL_LEN: ${VLLM_MAX_MODEL_LEN:-32768}
      HIP_VISIBLE_DEVICES: ${HIP_VISIBLE_DEVICES:-0}
      HSA_OVERRIDE_GFX_VERSION: ${HSA_OVERRIDE_GFX_VERSION:-11.5.0}
      HF_TOKEN: ${HF_TOKEN:-}
      MODEL_PATH: ${CORTEX_LANE_ORCHESTRATOR_MODEL_PATH}
    volumes:
      - cortex_models:/models:ro
      - vllm_cache:/root/.cache/huggingface
      - ./model-preflight.sh:/preflight/model-preflight.sh:ro
    shm_size: '16gb'
    networks:
      - cortex-network
    depends_on:
      model-preflight:
        condition: service_completed_successfully
    healthcheck:
      test: ["CMD-SHELL", "/preflight/model-preflight.sh \"${CORTEX_LANE_ORCHESTRATOR_MODEL_PATH}\" && curl -f http://localhost:8000/health"]
      <<: *healthcheck-defaults
      start_period: 180s
    deploy:
      resources:
        limits:
          memory: 48G
        reservations:
          memory: 40G

  # ===========================================================================
  # LLM Inference - llama.cpp (for SUPER_READER and GOVERNANCE)
  # ===========================================================================
  llama-cpp:
    # Set LLAMA_CPP_IMAGE to a pinned tag (e.g., ghcr.io/ggerganov/llama.cpp:server-rocm-0.2.90)
    image: ${LLAMA_CPP_IMAGE:?LLAMA_CPP_IMAGE must be set to a pinned tag (e.g., ghcr.io/ggerganov/llama.cpp:server-rocm-0.2.90)}
    container_name: cortex-llama-cpp
    <<: *restart-policy
    command: >
      --model ${CORTEX_LANE_SUPER_READER_MODEL_PATH}
      --ctx-size 131072
      --n-gpu-layers 99
      --host 0.0.0.0
      --port 8080
    devices:
      - /dev/kfd
      - /dev/dri
    group_add:
      - video
      - render
    environment:
      <<: *model-paths
      HIP_VISIBLE_DEVICES: ${HIP_VISIBLE_DEVICES:-0}
      HSA_OVERRIDE_GFX_VERSION: ${HSA_OVERRIDE_GFX_VERSION:-11.5.0}
    volumes:
      - cortex_models:/models:ro
      - ./model-preflight.sh:/preflight/model-preflight.sh:ro
    networks:
      - cortex-network
    depends_on:
      model-preflight:
        condition: service_completed_successfully
    healthcheck:
      test: ["CMD-SHELL", "/preflight/model-preflight.sh \"${CORTEX_LANE_SUPER_READER_MODEL_PATH}\" && curl -f http://localhost:8080/health"]
      <<: *healthcheck-defaults
      start_period: 120s
    deploy:
      resources:
        limits:
          memory: 32G
        reservations:
          memory: 16G

  # ===========================================================================
  # Workflow Automation - n8n
  # ===========================================================================
  n8n:
    image: n8nio/n8n:1.82.1
    container_name: cortex-n8n
    <<: *restart-policy
    environment:
      - N8N_BASIC_AUTH_ACTIVE=true
      - N8N_BASIC_AUTH_USER=${N8N_BASIC_AUTH_USER:?N8N_BASIC_AUTH_USER is required}
      - N8N_BASIC_AUTH_PASSWORD=${N8N_BASIC_AUTH_PASSWORD:?N8N_BASIC_AUTH_PASSWORD is required}
      - N8N_ENCRYPTION_KEY=${N8N_ENCRYPTION_KEY:?N8N_ENCRYPTION_KEY is required}
      - N8N_HOST=${CORTEX_DOMAIN:-localhost}
      - N8N_PORT=5678
      - N8N_PROTOCOL=https
      - WEBHOOK_URL=https://${CORTEX_DOMAIN:-localhost}/webhooks/
      - N8N_DIAGNOSTICS_ENABLED=false
      - EXECUTIONS_DATA_SAVE_ON_SUCCESS=none
      - EXECUTIONS_DATA_SAVE_ON_ERROR=all
      - EXECUTIONS_DATA_SAVE_MANUAL_EXECUTIONS=true
      - EXECUTIONS_DATA_PRUNE=true
      - EXECUTIONS_DATA_MAX_AGE=168  # 7 days
      - N8N_USER_MANAGEMENT_DISABLED=true
    volumes:
      - n8n_data:/home/node/.n8n
    networks:
      - cortex-network
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:5678/healthz"]
      <<: *healthcheck-defaults

  # ===========================================================================
  # Backend - FastAPI
  # ===========================================================================
  backend:
    build:
      context: ..
      dockerfile: Dockerfile.backend
    container_name: cortex-backend
    <<: *restart-policy
    environment:
      <<: [*common-env, *model-paths]
      CORTEX_LANE_ORCHESTRATOR_URL: http://inference-vllm:8000/v1
      CORTEX_LANE_CODER_URL: http://inference-vllm:8000/v1
      CORTEX_LANE_FAST_RAG_URL: http://inference-vllm:8000/v1
      CORTEX_LANE_SUPER_READER_URL: http://llama-cpp:8080/v1
      CORTEX_LANE_GOVERNANCE_URL: http://llama-cpp:8080/v1
      CORTEX_CELERY_BROKER_URL: redis://redis:6379/0
      CORTEX_CELERY_RESULT_BACKEND: redis://redis:6379/0
      CORTEX_TASKS_EAGER: "0"
    volumes:
      - backend_data:/app/data
      - cortex_models:/models:ro
      - storage_uploads:/app/storage_uploads
    depends_on:
      postgres:
        condition: service_healthy
      qdrant:
        condition: service_healthy
      migrations:
        condition: service_completed_successfully
    networks:
      - cortex-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/api/system/health"]
      <<: *healthcheck-defaults
    deploy:
      resources:
        limits:
          memory: 4G
        reservations:
          memory: 2G

  # ===========================================================================
  # Celery Worker - Ingest queue
  # ===========================================================================
  celery-worker:
    build:
      context: ..
      dockerfile: Dockerfile.backend
    container_name: cortex-celery-worker
    <<: *restart-policy
    command: >
      celery -A app.worker.celery_app worker
        -Q ingest
        --loglevel=info
    environment:
      <<: [*common-env, *model-paths]
      CORTEX_CELERY_BROKER_URL: redis://redis:6379/0
      CORTEX_CELERY_RESULT_BACKEND: redis://redis:6379/0
      CORTEX_TASKS_EAGER: "0"
    depends_on:
      redis:
        condition: service_healthy
      postgres:
        condition: service_healthy
      qdrant:
        condition: service_healthy
      migrations:
        condition: service_completed_successfully
    networks:
      - cortex-network
    volumes:
      - cortex_models:/models:ro
      - storage_uploads:/app/storage_uploads
    healthcheck:
      test: ["CMD-SHELL", "celery -A app.worker.celery_app inspect ping -d celery@$$HOSTNAME"]
      <<: *healthcheck-defaults
      start_period: 30s

  # ===========================================================================
  # Observability - Prometheus (optional)
  # ===========================================================================
  prometheus:
    image: prom/prometheus:v2.54.0
    container_name: cortex-prometheus
    <<: *restart-policy
    command:
      - "--config.file=/etc/prometheus/prometheus.yml"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus_data:/prometheus
    ports:
      - "9090:9090"
    networks:
      - cortex-network
    depends_on:
      backend:
        condition: service_healthy

  # ===========================================================================
  # Frontend Builder - Build and serve React app
  # ===========================================================================
  frontend-builder:
    build:
      context: ..
      dockerfile: Dockerfile.frontend
      target: builder
      args:
        VITE_CORTEX_API_BASE_URL: https://${CORTEX_DOMAIN:-localhost}
        VITE_CORTEX_WS_BASE_URL: wss://${CORTEX_DOMAIN:-localhost}
    container_name: cortex-frontend-builder
    environment:
      VITE_CORTEX_API_BASE_URL: https://${CORTEX_DOMAIN:-localhost}
      VITE_API_BASE_URL: https://${CORTEX_DOMAIN:-localhost}
      NODE_ENV: production
    volumes:
      - frontend_dist:/app/dist
    command: sh -c "pnpm build && cp -r dist/* /app/dist/"

  # ===========================================================================
  # Database Migrations
  # ===========================================================================
  migrations:
    build:
      context: ..
      dockerfile: Dockerfile.backend
    container_name: cortex-migrations
    environment:
      <<: *common-env
    command: >
      sh -c "
        echo 'Waiting for PostgreSQL...' &&
        while ! pg_isready -h postgres -U cortex -d cortex; do sleep 2; done &&
        echo 'Running Alembic migrations...' &&
        cd /app && alembic upgrade head &&
        echo 'Migrations complete!'
      "
    depends_on:
      postgres:
        condition: service_healthy
    networks:
      - cortex-network
    restart: "no"

# =============================================================================
# Volumes
# =============================================================================
volumes:
  # Persistent data
  postgres_data:
    driver: local
  qdrant_data:
    driver: local
  qdrant_snapshots:
    driver: local
  n8n_data:
    driver: local
  backend_data:
    driver: local
  storage_uploads:
    driver: local
  vllm_cache:
    driver: local
  prometheus_data:
    driver: local
  
  # Caddy
  caddy_data:
    driver: local
  caddy_config:
    driver: local
  
  # Frontend static files
  frontend_dist:
    driver: local
  
  # Models - mount from host
  cortex_models:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ${MODELS_PATH:?MODELS_PATH is required}

# =============================================================================
# Networks
# =============================================================================
networks:
  cortex-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.28.0.0/16
